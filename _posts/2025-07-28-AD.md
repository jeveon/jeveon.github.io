---
layout: post
title: "[논문 리뷰] PromptAD: Zero-shot Anomaly Detection using Text Prompts"
categories: Paper
excerpt_image: /assets/images/2025-07-28-AD/Untitled-20250728132258370.webp
tags: [Zero-Shot Anomaly Detection, Prompts]
---

Li, Yiting, et al. "Promptad: Zero-shot anomaly detection using text prompts." Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision. 2024. https://openaccess.thecvf.com/content/WACV2024/html/Li_PromptAD_Zero-Shot_Anomaly_Detection_Using_Text_Prompts_WACV_2024_paper.html

## 1. Introduction

Anomaly Detection(AD)는 산업 제품 검사, 네트워크 보안, 자율 주행 등 다양한 응용 분야에서 중요한 역할을 한다. 하지만 대부분의 모델은 학습 과정에서 관찰한 클래스에 대해서만 사용이 가능하다. 이에 반해 실제 환경에서는 모델이 본 적 없는 새로운 class도 이상을 탐지해야 한다.

이러한 cross-category generalization 문제를 풀기 위해서 본 논문은 Zero-Shot Anomaly Detection(ZSAD) 문제를 다룬다. 이는 아래 그림과 같은 상황을 말한다. 

![a](/assets/images/2025-07-28-AD/Untitled-20250728132258370.webp)

ZSAD는 unseen class의 실제 data를 사용할 수 없기 때문에 매우 어려운 과제이다. 여기에 더불어 normal data에서 기대되는 특성이나 anormal에 대한 정보는 종종 시각적 예시 없이 존재한다. 

CLIP과 같은 Vision-Language Models의 등장으로 자연어 정보를 활용해서 정상과 이상에 대한 의미론적 표현을 얻을 수 있으며, 이는 시각적 예시가 없는 상황에 사용되거나 이상 탐지 성능을 향상하는데 사용된다. 

이러한 배경에서 본 연구는 PromptAD라는 framework를 제안한다. 이 모델은 text로 부터 얻은 정보를 활용해서 정상과 이상 각각에 대해 정보를 제공함으로서 이미지 data에 대한 의존도를 줄인다. 


## 2. Related Work

기존의 방식은 unsupervised method와 supervised method가 존재하지만 이 방식들은 unseen class에 대한 이상 탐지는 취약하다.


## 3. Anomaly Detection with Anomaly-Aware Text Prompts

### 3.1 Problem Description

ZSAD는 다음과 같이 정의된다. 모델은 base class(seen class)에 속하는 정상 sample N개와 소수의 이상 샘플로 구성된 base data를 사용해서 학습된다. 이후 학습 없이 새로운 class 집합에 대해 모델을 testing 한다. 

또한 전체 class 집합에 대해서 정상 패턴의 시각적 특성을 설명하는 normality branch와 일반적인 이상 패턴을 설명하는 abnormality prompt가 존재한다. 본 논문의 목표는 base data만을 사용해서 학습을 한 후 unseen class에서 이상을 탐지하는 것이다.

### 3.2 PromptAD Framework

본 논문에서 제안하는 framework는 아래와 같다. 

![a](/assets/images/2025-07-28-AD/Untitled-20250728133829471.webp)

공통된 CLIP 모델 위에 abnormality branch와 normality branch로 구성이 된다. abnormality branch에서는 abnormality prompt를 기반으로 이상 샘플의 분포를 직접 모델링 하며, normality branch는 normal sample의 분포를 모델링해서 query 이미지가 normality text 설명과 얼마나 잘 일치하는지 측정한다. 또한 이 두 view간의 상호 보완적인 지식 전달을 위해서 Cross-view Contrastive Learning(CCL)과 Cross-view Mutual Interaction(CMI)를 사용한다.

### 3.3 Intra-view Modeling

#### 3.3.1 Abnormality Branch

주어진 이미지에 대해서 CLIP image encoder를 사용해서 시각 embedding을 추출하고, abnormality prompt에 대해서 CLIP text encoder를 통해서 sematic embedding을 추출한다. 그리고 이를 FiLM(Film Lyaer)기법을 사용해서 융합한다. 

이렇게 융합된 feature는 tranformer-based decoder를 통과하여 공간적 위치별 이상점수를 출력한다. 그리고 이는 단일 시각 이상 점수(Intra-view Abnormality Score, $s_{abn}^{intra}$)라고 부른다. abnormality prompt에 해당하는 이상 영역은 정상 영역보다 더 높은 이상 점수를 가지도록 유도 된다. 

#### 3.3.2 Normality Intra-view Modeling

Abnomality branch와 비슷한 decoder 구조를 가지지만 normality prompt로 정의된 정상 profile과 query 이미지 간의 일치도를 직접 측정하는 것을 목표로 한다. 이 branch에서는 단일 시각 정상 점수(Intra-view Normality Score)를 예측한다.




### 3.4 Cross-view Contrastive Learning

### 3.4.1 Abnormality Branch

![a](/assets/images/2025-07-28-AD/Untitled-20250728134547590.webp)

![a](/assets/images/2025-07-28-AD/aa.png)

normality prompt를 CLIP text encoder에 통과시켜 얻은 semantic embedding과 query image로 부터 추출한 단일 시각 이상 특징과 비교해서 Cross-view Normality Score($s_{nor}^{cross}$)를 계산한다. 이 값은 Intra-view Abnormality Score과 반대로 값이 클수록 정상일 가능성이 높다. 따라서 이를 이용해서 1번식과 같이 Abnormality branch에서 이상 점수를 구한다. 

### 3.4.2 Normality Branch

3.4.1 과 유사하게 abnormality prompt를 CLIP text encoder에 통과 시켜 얻은 semantic embedding과 query image로 부터 추출한 단일 시각 정상 특징과 비교해서 Cross-view Abnormality Score($s_{abn}^{cross}$)를 계산한다. 이 값은 값이 클수록 이상일 가능성이 높음을 나타내며 최종적으로 normality branch에서 이상 점수는 2번 식과 같이 구해진다.

### 3.5 Cross-view Mutual Interaction

위에서 설명한 두가지 branch를 각각 학습하기 보다 상호 작용(Mutual interaction)을 통해서 서로 이득을 얻을 수 있다고 보았다. 따라서 한 branch의 중간 attention을 활용해서 다른 branch가 놓친 잠재적인 이상 영역을 확장하도록 한다. 

예를 들어 설명하면, 정산 branch에서 얻은 anomaly score map을 Relu와 sigmoid 함수를 통과시켜 이상 영역만을 남겨둔 후 해당 영역에 가중치를 곱해줌으로써 이상을 강조한다. 이러한 방식을 두 branch에 적용해서 한 branch가 놓친 이상도 다른 branch의 attention으로 효과적인 탐지가 가능하다.

### 3.6 Training and Inference

정상 샘플과 이상 샘플 사이의 점수 분포에서 의미 있는 편차(deviation)을 위도 하기 위해서 Symmetric Deviation Loss를 사용한다. 또한 편향 없는 anomaly 분류를 위해서 normality branch와 abnormality branch의 점수를 결합해서 anomaly score를 계산한다.


## 4. Experiments

실험은 MVTec AD와 AITEX dataset으로 수행이 되며, 하나의 카테고리를 테스트 대상으로 선택하고 나머지 카테고리들을 모델학습에 사용하는 방식인 leave-one-category-out 방식으로 진행되었다.

또한 이상 labeling data가 부족한 현실을 반영해서 각 학습 대상 class에서 임의로 선택된 하나의 이상 타입으로 부터 단 1개 또는 10개의 labeling된 이상 sample만을 활용하였다. 

성능 평가기준은 ROC이며, 10회 반복실험의 평균값으로 실험결과를 내었다.

normality prompt는 Oxford 영어 사전 정의를 기반으로 구성되었으며, abnormality prompt는 시각적 특징에 대해 사전 지식을 서술하는 방식으로 구성되었다. 

이미지 증강 방식을 사용하지 않으며, 학습은 support-query 방식으로 수행된다. 이는 학습 episode에서 label이 부여된 몇 개의 query 이미지가 sampling되며, 두 가지 branch에서 학습된다. 

DevNet, MLEP, DRA, WinCLIP, CLIP과 비교 하였으며, 아래는 실험 결과이다. 

![a](/assets/images/2025-07-28-AD/Untitled-20250728143423694.webp)

![a](/assets/images/2025-07-28-AD/Untitled-20250728143433372.webp)

![a](/assets/images/2025-07-28-AD/Untitled-20250728143442354.webp)

![a](/assets/images/2025-07-28-AD/Untitled-20250728143454543.webp)
