---
layout: post
title: Prompt Engineering
categories: Report
excerpt_image: /assets/images/Prompt/1.png
tags: [Prompt Engineering, LLM]
---

Prompts are natural language text that asks a generative AI to perform a specific task.

Large language models (LLMs) are very flexible and can perform many different tasks. However, they are also very open-ended, meaning that a change in a single prompt word can cause the system to generate a detailed response.

However, not all types of input will produce useful output; generative AI systems need context and detail to generate accurate and relevant responses. By systematically designing prompts, you can achieve more meaningful and useful outputs.

![Prompt Engineering-20250207151912989.webp](/assets/images/Prompt/1.webp)

This table is taken from the paper "Large Language Models are Zero-Shot Reasoners" published in 2022.

As you can see, typing "Let's think step by step." into the prompt results in higher accuracy compared to the other inputs. However, "Let's think like a detective step by step." is less accurate.

So we can get better answers by making sure that we're feeding the model the right inputs. Now, let's look at some more simple engineering techniques. In this presentation, I'll cover five techniques.

## Zero-shot
The first is zero-shot prompting.

This is like the one we use all the time. We just present the question we want to ask, and a given situation. Like the example you see, where you're asked if a sentence is positive, negative, or neutral, and you're given a sentence and asked to answer.

![Pasted image 20250207152047.png](/assets/images/Prompt/2.png)

## Few-shot
The next approach is called few-shot prompting.

![Prompt Engineering-20250207152034212.webp](/assets/images/Prompt/3.webp)

This is a technique that allows for in-context learning, where the prompts provide a demonstration to guide the model to perform better. When it sees an example, it determines the state of several sentences and asks questions about the desired sentence. If it finds the task more challenging, it can increase the number of examples to get results.

When using Few-shot, performance improves even when individual inputs are not correct, as in the example shown here. "This is bad" is a negative sentence, but the output is still correct in the end.

And even using just random labels, as shown below, yields much better performance than no labels at all.

But there are still limitations. For complex reasoning, the performance of the few-shot approach is poor.

The example on the right is the problem of determining whether the sum of a group is even or odd. We think this is a very simple problem, but the few-shot method gives the wrong result, and the same result is obtained with more shots.


## CoT Prompting

To solve this problem, we use Chain-of-Thought (CoT) Prompting. Chain-of-thought (CoT) prompts allow for complex reasoning with intermediate reasoning steps. Combine this with short-answer prompts and you get better results on complex tasks that require reasoning before responding. Adding just one example is enough to address this challenge:

If we put the process of getting the right answer into the prompt, as in the example shown, we would get more accurate results.

![Prompt Engineering-20250207152121424.webp](/assets/images/Prompt/4.png)
“Chain-of-Thought Prompting Elicits Reasoning in Large Language Models” , Wei et al., 2022


## Self-Consistency

The above CoT can be further improved: it's called self-consistency. A few-shot CoT samples several different reasoning paths, generates multiple prompts, and selects the most consistent answer. This can improve the performance of chain-of-think prompts on tasks involving arithmetic and common-sense reasoning.

By showing the different ways to arrive at the correct answer, we can show better answers.

![Prompt Engineering-20250207152154190.webp](/assets/images/Prompt/5.webp)
“Self-Consistency Improves Chain of Thought Reasoning in Language Models” , Wang et al.,2022

## ReAct prompting

ReAct is inspired by the synergy between "action" and "reasoning" that enables humans to learn new tasks and make decisions or inferences. ReAct drives large-scale language models to generate linguistic reasoning traces and actions for a task. This allows the system to create, maintain, and adjust plans for its actions, while incorporating additional information into its reasoning through interaction with the external environment.

In "Thought," you write down the question you want to ask, and then in "Act," you write down how you want to find the answer to the question - in this example, you search for Apple remote. Then in "Observe," you see what you find through your actions and move on to the next Thought. When we put this process together with our questions, we can extract very high performance.

![Pasted image 20250207152215.png](/assets/images/Prompt/6.png)

This is currently being attempted in a variety of ways.  However, even with these advances, we have doubts that we will ever be able to use them in practice: we will always need to modify the prompts to get the answers in the areas we want.

So, let me introduce you to one site that can solve this problem.

## Poe (artificial intelligence chatbot service)

POE is a platform developed by Quora, an American question and answer website. Quora, which has 600 million users as of 2021, is using data from the site to create a generative AI platform.

You can also set up a knowledge base for answers and make them refer to specific sites.

Some chatbots, like the one you see on the screen, tell you how to ask someone out on a date.

I asked how to ask someone out on a date and got a lot of advice on how to do that. There are other chatbots that specialize in coding or academics, for example.

## Conclusion

Generative AI can perform as well as humans, books, and the internet, and it can interact with a wide range of knowledge, so I think it will become increasingly useful for acquiring knowledge in society. I also think it will one day surpass books and people.
