---
layout: post
title: "[논문 리뷰] Single shot active learning using pseudo annotators"
categories: Paper
excerpt_image: /assets/images/single-2025-07-22/Untitled-20250722103554961.webp
tags: [Single Shot Active Learning, Random Labeling, Nearest Neighbor Distance]
---


Sener, Ozan, and Silvio Savarese. "Active learning for convolutional neural networks: A core-set approach." _arXiv preprint arXiv:1708.00489_ (2017). https://arxiv.org/abs/1708.00489


## 1. Introduction

CNN은 image classification, object detection, scene segmentation과 같은 연구 분야에서 많은 성공을 거두었지만 많은 양의 labeled data가 필요하다는 것은 여전히 문제로 남아있다. 

Dataset에 labeling하는 작업은 시간과 비용이 많이 든다. 따라서 고정된 예산 내에서 가장 높은 정확도를 얻기 위해. Active learning 기반으로 data를 선별한다.

기존의 heuristic 한 기법은 CNN을 학습하는데 어려움이 있다. 기존 AL 알고리즘은 한 번에 하나의 data를 선택하지만 CNN의 경우 단일 data는 local optimization 때문에 정확도에 영향을 주지 못할 가능성이 크며, 각 반복마다 모델을 완전히 학습해야하기 때문에 하나씩 label을 요청하는 방식은 많은 자원이 소모되게 된다. 따라서 한 번에 다수의 sample을 선택하는 방식이 필요하지만 이도 중복된 data를 포함할 가능성이 있다.

이러한 문제를 해결하기 위해서 AL문제를 Core-set 선택문제로 정의를 하여서 unlabeled data pool에서 작은 부분 집합을 선택해 그 부분집합으로 모델을 학습해 좋은 성능을 내도록 한다. 또한 unlabeled data를 쓰기 때문에 본 연구에서는 data의 기하적 특성을 사용한다. 주어진 부분집합과 나머지 데이터 간의 average loss의 상한을 수학적으로 제시해 이를 최소화 하는 부분집합을 선택해 labeling을 하고자 한다. 


## 2. Related Work

기존에 익히 알고 있는 information theoretical methods, ensemble approaches, uncertainty based method들이 존재하지만 이들은 대규모 dataset에서 성능이 떨어진다. 

본 논문에서 제안하는 방식은 기존에 많이 사용하던 AL방식과 다르게 불확실성 정보를 전혀 사용하지 않는다. 

Core-set 문제를 특정 학습 알고리즘에 적용한 경우는 있지만 CNN에 적용한 경우는 없다. 또한 제안하는 기법은 semi-supervised learning과 관련이 있다.


## 3. Problem Definition

$$\min_{s_1: |s_1| \leq b} \mathbb{E}_{(x, y) \sim p_Z} \left[ l(x, y; A_{s_0 \cup s_1}) \right] \tag{1}$$
$$\min_{s_{k+1}: |s_{k+1}| \leq b} \mathbb{E}_{(x, y) \sim p_Z} \left[ l(x, y; A_{s_0 \cup \cdots \cup s_{k+1}}) \right] \tag{2}$$

AL 학습 문제는 1번과 같이 정의 된다. 여기서 A는 active learning 기법이며, b는 query burget이다. 전통적인 방법은 burget이 1인 경우를 다루지만 deep learning의 경우 단일 data가 미치는 영향이 적기 때문에 batch 환경을 고려한다. 

또한 이러한 과정을 여러 round에 걸쳐 반복하는 것이 일반적이다. 본 논문도 round 기반 방식을 따르며 각 round에서는 근시안적(myopic) 방식으로 2번 식과 같은 최적화 문제를 풀게 된다. 하지만 본 논문에서는 간결성을 위해서 1번 식에 초점을 맞춰서 설명을 진행하며, 실제 실험은 다수의 round에 대해서 진행된다.

각 round에서는 labeling할 데이터를 선택한 후 Oracle에 query를 하고 기존의 data와 새롭게 labeling된 data를 이용해 classifier를 학습한다. classifier를 학습할 때, labeling data만 활용하는 fully-supervised 방식과 unlabel data도 함께 활용하는 weakly-supervised 방식이 있으며, 기존 연구에서는 fully-supervised 방식만을 다루지만 본 논문에서는 두 경우 모두 실험하고 testing 한다.


## 4. Method

### 4.1 Active Learning as a set cover

![[Untitled-20250724141912063.webp]]

$$\mathbb{E}_{x,y \sim p_Z} [l(x, y, A_s)] \leq \underbrace{\left( \mathbb{E}_{x,y \sim p_Z} [l(x, y, A_s)] - \frac{1}{n} \sum_{i \in [n]} l(x_i, y_i, A_s) \right)}_{\text{Generalization Error}}
$$$$+ \underbrace{\frac{1}{|s|} \sum_{j \in s} l(x_j, y_j, A_s)}_{\text{Training Error}} + \underbrace{\left( \frac{1}{n} \sum_{i \in [n]} l(x_i, y_i, A_s) - \frac{1}{|s|} \sum_{j \in s} l(x_j, y_j, A_s) \right)}_{\text{Core-Set Loss}} \tag{3}$$
$$\min_{s_1: |s_1| \leq b} \left[ \frac{1}{n} \sum_{i \in [n]} l(x_i, y_i, A_{s_0 \cup s_1}) - \frac{1}{|s_0 \cup s_1|} \sum_{j \in s_0 \cup s_1} l(x_j, y_j, A_{s_0 \cup s_1}) \right] \tag{4}$$

$$\left| \frac{1}{n} \sum_{i \in [n]} l(x_i, y_i, A_s) - \frac{1}{|s|} \sum_{j \in s} l(x_j, y_j, A_s) \right| \leq \epsilon_s (\tau_l + \tau_\eta LC) + \sqrt{ \frac{L^2 \log(1/\delta)}{2n} } \tag{4.1}$$

Batch 설정에 효과적인 AL 전략을 설계하기 위해서 1번 식에서 정의한 Active learning loss에 대해서 3번 식과 같은 상한을 고려한다. Core-set loss는 labeling된 data과 전체 dataset에서의 평균 경험적 loss의 차이이다. CNN은 표현력이 매우 뛰어나기 때문에 일반화가 잘 이루어지며, 따라서 Generalization Error 부분을 제외하고 AL 문제를 4번 식과 같이 재정의 할 수 잇다. 

4번 식에서 정의된 최적화 목적은 active learning 환경이기 때문에 직접 계산할 수 없다. 따라서 이에 4.1번 식과 같은 계산 가능한 상한을 제시한다. 이 상한은 Training loss가 0이라는 가정을 한다. 또한 Loss function이 Lipschitz 연속성을 가져야하는데 이는 보조 정리를 통해서 증명하였다.

이 식을 자세히 해석하면 $s$의 각 점을 중심으로 하는 반지름 ϵ를 가진 구가 전체 $s^*$을 덮을 수 있다는 것을 의미한다. 또한 이 상한은 label 수와 관련이 없으며, 제공된 label이 ϵ를 줄이지 않는 한, Core-set Loss 개선에 기여하지 않는다는 것을 의미한다.

결국 이 문제는 반지름 ϵ를 최소화 하는 문제가 되고 k-Center 문제와 동등하게 된다. 

### 4.3 Solving the K-Center Problem


$$\min_{s_1: |s_1| \leq b} \max_i \min_{j \in s_1 \cup s_0} d(x_i, x_j) \quad \tag{5}$$
$$\text{OPT} = \min_{s_1} \max_i \min_{j \in s_1 \cup s_0} d(x_i, x_j) \tag{5.1}$$
$$\max_i \min_{j \in s_1 \cup s_0} d(x_i, x_j) \leq 2 \times \text{OPT} \tag{5.2}$$

k-Center 문제는 5번 식과 같이 정의 된다. 모든 data와 가장 가까운 Center 사이의 최대 거리를 최소화 하도록 b개의 중심점을 선택하게 된다. 이 문제는 NP-Hard problem (Non-deterministic Polynomial time, 풀기 어려운 문제 정도)이지만 Greedy 접근 방식을 사용하면 $2 \times \text{OPT}$ 이하의 해를 효율적으로 얻을 수 있다.

이 해는 좋은 초기 값을 제공하지만, 실제에서는 이보다 더 나은 해를 얻기 위해서 최적의 상한을 반복적으로 질의하는 방식으로 개선할 수 있으며, 이를 위해 mixed integer program (MIP)를 정의하여 최적값이 $\delta$이하일 때 실현 가능하도록 설계되었다. 여기에 더불어 robustness 부족을 보완하기 위해서 unlabeled 데이터 중 최대 outlier 수를 제한하는 방법도 도입했다.

![[Untitled-20250724145321557.webp]]

### 4.4 Implementation Details

weakly-supervised learning에서는 Ladder Network (Rasmus et al., 2015)를 사용하였으며, 모든 실험에서는 VGG-16 (Simonyan & Zisserman, 2014) CNN을 사용했다. 최적화는 RMSProp, learning rate는 1e−3으로 설정하였다.


## 5. Experimental Results

CIFAR, SVHN dataset을 사용했으며, CIFAR의 경우 10개의 class에 대한 coarse-grained 분류에 대한 실험 100개의 class에 대한 fine-grained 분류에 대해서 실험했다. 

비교 방법들은 Random, Best Empirical Uncertainty, DBAL (Deep Bayesian Active Learning), Best Oracle Uncertainty, k-Median, BMDR (Batch Mode Discriminative-Representative Active Learning), CEAL (Wang et al., 2016)을 사용하였다. 

총 다섯번 초기 label pool을 무작위로 초기화 했고 평균 분류 정확도를 평가 지표로 사용하였다. 아래는 실험결과에 대한 그림이다.

![[Untitled-20250724150336602.webp]]

![[Untitled-20250724150349497.webp]]
