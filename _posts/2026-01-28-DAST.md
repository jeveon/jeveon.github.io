---
layout: post
title: "[논문 리뷰] DAST-Net: Dense visual attention augmented spatio-temporal network for unsupervised video anomaly detection"
categories: Paper
excerpt_image: /assets/images/2026-01-28-DAST/1.webp
tags: [Video surveillance, Video anomaly detection, Unsupervised learning]
---

Kommanduri, Rangachary, and Mrinmoy Ghorai. "DAST-Net: Dense visual attention augmented spatio-temporal network for unsupervised video anomaly detection." _Neurocomputing_ 579 (2024): 127444.
https://www.sciencedirect.com/science/article/pii/S0925231224002157


## 1. Introduction

Video Anomaly Detection은 비디오에서 비정상적인 사건이나 활동을 자동으로 식별하는데 초점을 맞춘 연구분야 이다. 이는 보안 목적이나 교통 흐름 또는 군중 행동 모니터링과 같은 다양한 응용 분야에서 사용가능 하다. 해당 분야는 다양한기술이 개발되었지만 여전히 효율성이 부족하다. 이상 현상의 유형을 판별하는게 어려우며 이상 현상은 빈도가 낮고 예상치 못한 경우가 많다. 더불어 발생 맥락에 따라 달라지는 경우도 존재한다. 따라서 이상 징후를 식별하기 위해서는 정상 행동에 대한 명확한 이해가 필수적이다. 

시공간 모델(Spatio-temporal models)은 해당 분야에서 선호되고 잇는 방식이며, 맥락적 이해 동작 패턴 분석, 시간적 일관성 유지, 그리고 공간적 및 시간적 특징의 원할한 통합으로 인해서 많이 사용된다. 이상 현상의 발생 빈도가 낮기 때문에 이러한 모델은 비지도 학습 방식으로 구현된다. 

최근 딥러닝 기반 방법들이 발전해 왔으며, 이러한 방법들은 대부분 입력 프레임을 재구성 하거나 미래 프레임을 예측하기 위해서 모델을 사용한다. 이러한 방식의 한계는 당므과 같다. 공간적 특징과 시간적 특징을 모두 효과적으로 추출할 수 없으며, 전경과 배경이 동등하게 취급된다는 문제점이다. 이러한 문제를 해결하기 위해서 본 논문은 DenseResNet을 제안한다. 

## 2. Related Work

VAD는 과거 궤적이나 Histogram of oriented gradients (HOG) 같은 수작업 특징을 활용하는 방식에서 시작되었지만 보다 복잡한 환경을 극복하기 위해서 최근에는 딥러닝 기반이 주를 이룬다. 딥러닝 기반 방식은 CNN, Autoencoder, LSTM 등을 통해서 영상의 시공간적 특징과 움직임 패턴을 학습하고, 또한 이를 극대화하기 위해서 Memory module, Two-steam Acrhitectual, Attension 과 같은 방식이 사용된다. 


## 3. Proposed framework

![a](/assets/images/2026-01-28-DAST/1.webp)

![a](/assets/images/2026-01-28-DAST/2.webp)
본 논문에서는 위 그림과 같은 모델을 제안한다. 네트워크가 입력 이미지 또는 특징 맵 내의 중요한 공간 위치에 선택적으로 집중할 수 있도록, 네트워크의 각 잔여 연결에 시각적 어텐션 모듈을 도입했다. 또한 시간적 변화를 포착하기 위해 공간 인코더와 디코더 모듈 사이에 Temoral AE를 사용하였다. 


### **3.1. Background: ResNet vs. DenseNet**

아래 그림은 현재 제안된 모델과 기존에 존재하는 CNN, ResNet과의 차이점을 보여주는 그림이다. CNN은 단순히 레이어를 추가해서 학습하는 (a) 와 같은 형태이며, 이때 기울기 소실 문제가 발생할 수 있기 때문에 (b)와 같은 ResNet이 도입되었다. 

ResNet과 (c) DenseNet의 차이는 ResNet의 경우 Layer 별 feature를 합산하지만 DenseNet은 feature 특징을 concatenation 한다는 점이다. (이때 사용하는 함수는 concatenation operation이다.) 이러한 모델은 더 많은 GPU 메모리를 소비할 수 있지만 학습 및 정확도 측면에서 효율적인 경우가 많다. 

이러한 Background에서 본 논문은 DenserResNet이라는 아키텍쳐를 제안한다. 제안된 모델은 각 레이어가 이전의 모든 특징 맵과 밀접하게 연결된 ResNet 아키텍처를 말한다. ResNet에 비해서 더 복잡한 연결 패턴을 제공함으로서 모델의 성능을 향상 시킨다. 
![a](/assets/images/2026-01-28-DAST/3.webp)

### 3.2. Dense feature extraction and learning

제안된 모델은 총 3개의 요소로 구성된다. Spatial encoder-decoder, Visual attention-aware module, Temporal autoencoder

#### 3.2.1. Spatial encoder-decoder

Encoder와 Decoder는 총 4개의 블록으로 이루어져 있으며, 각 블록은 세 개의 컨볼루션 레이어로 이루어져있다. 인코더는 이미지를 압축하고 디코더는 업샘플링하고 복원한다. 

#### 3.2.2. Visual attention-aware module

제안된 Attention은 모든 이전 레이어와 공유되는 공간적 특징을 밀집된 방식으로 활용한다. 아래 그림과 같이 모듈이 구성되어 있다. 아래와 같은 과정을 Encoder와 Decoder에 적용한다. 
![a](/assets/images/2026-01-28-DAST/4.webp)
![a](/assets/images/2026-01-28-DAST/5.webp)

#### 3.2.3. Temporal autoencoder

제안된 모델은 정상적인 행동과 비정상적인 행동을 구분하는 패턴을 포착하기 위해 ConvLSTM 모델을 사용해서 AE를 만들어서 사용하였다. 

### 3.3. Training and objective function

이미지 재구성 Loss를 사용하며, 연속된 5개의 프레임을 통해서 Loss를 계산한다. 

Intensity Loss (강도 손실) : 원본 이미지와 재구성된 이미지 간의 픽셀 값 차이(유클리드 거리)를 계산한다. 이 손실은 이미지가 약간 흐릿하게 복원되는 경향이 있다. 

![a](/assets/images/2026-01-28-DAST/cc.png)

$$\hat{I}_t$$ 는 모델이 생성한 재구성 프레임이며, $$I_t$$는 입력값이다. 

Gradient Loss (기울기 손실): 이미지의 선명도를 유지하기 위해, 픽셀 간의 변화량 차이를 계산합니다. $i$와 $j$는 공간 좌표(가로, 세로)를 의미한다. 이 loss는 제대로 복원 못한 이상 데이터와의 차이를 벌리는 역할을 한다. 

![a](/assets/images/2026-01-28-DAST/aa.png)

위 두 가지 손실을 가중치($\lambda$)를 적용하여 합친 최종 손실 함수를 구한다. 

![a](/assets/images/2026-01-28-DAST/bb.png)

### 3.4. Regularity score function and anomaly detection

모델의 학습이 끝난 후 PSNR(Peak Signal-to-Noise Ratio)지표를 사용해서 두 변수 간의 유사도를 계산한다. 수식은 아래와 같다. PSNR 값이 높을 수록 정상일 가능성이 높다는 것을 의미한다. 
$$L(t) = 10 \cdot \log_{10} \left( \frac{\max_{\hat{I}}^2}{\frac{1}{n} \sum_{i=0}^{n} (I_i - \hat{I}_i)^2} \right)$$
이제 이를 정규화 하여 정상성 점수를 결정한다.
$$S(t) = \frac{L(t)-\min(L)}{\max(L)-\min(L)} $$
## 4. Experiments and results

### 4.1. Datasets

 UCSD Pedestrian, CUHK Avenue, ShanghaiTech Campus 데이터 셋 사용

### 4.2. Evaluation metric

ROC Curve 아래 면적 AUC를 모델 평가 지표로 사용하였다. AUC를 사다리꼴 공식을 통해서 계산해서 사용하였다. AUC 값이 높을 수록 모델의 성능이 우수함을 의미한다. 
### 4.3. Preprocessing

RGB를 회섹조로 변환하여 모델이 필수적인 시각 정보에 집중할 수 있도록 한다. 또한 일관된 강도 스케일을 유지하기 위해 각 프레임의 픽셀 강도를 정규화 한다. 

### 4.4. Experimental settings

Adam optimizer, batch size 16, 각 데이터 셋 별로 epoch 다름 60, 120, 180

### 4.5. Results and analysis

ConvLSTM+AE, R-STAE, U-Net+Pred, Bi-READ와 같은 다양한 방법론들과 비교, 실험 결과는 아래와 같다. 다양한 파라미터에 대한 실험도 진행

![a](/assets/images/2026-01-28-DAST/6.webp)

![a](/assets/images/2026-01-28-DAST/8.webp)

![a](/assets/images/2026-01-28-DAST/9.webp)

![a](/assets/images/2026-01-28-DAST/10.webp)

![a](/assets/images/2026-01-28-DAST/11.webp)

![a](/assets/images/2026-01-28-DAST/12.webp)
