---
layout: post
title: "[논문 리뷰] Adaptive local-component-aware graph convolutional network for one-shot skeleton-based action recognition"
categories: Paper
excerpt_image: /assets/images/2025-07-30-GCN/Untitled-20250729211939471.webp
tags: [Action Recognition, One-Shot Learning, Graph Convolutional Network]
---

Zhu, Anqi, et al. "Adaptive local-component-aware graph convolutional network for one-shot skeleton-based action recognition." _Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision_. 2023. https://openaccess.thecvf.com/content/WACV2023/html/Zhu_Adaptive_Local-Component-Aware_Graph_Convolutional_Network_for_One-Shot_Skeleton-Based_Action_Recognition_WACV_2023_paper.html

## 1. Introduction

Action Recognition은 중요한 computer vision 문제 중 하나이다. 기본적으로는 RGB기반 입력에 집중했지만 이는 배경, 밝기, 색상 변화 등 작업과 무관한 요소에서 혼란을 겪을 수 있다.

그에 따라 3-D skeleton sequence가 부상하고 있다. 이 방식은 시간에 따른 3D 관절 움직임만 기록해서 외부 요인의 영향이 적다. 이를 통해서 알려진 활동들에 대해서 높은 정확도로 분류가 가능하지만 처음 보는 class(action)로 확장하는 연구는 아직 초기 단계에 머물러 있다.

이러한 상황에서 소수의 sample에 대해서 supervised learning을 진행해 새로운 class에 빠르게 적응하는 Few-shot learning이 주목 받고 있으며, 특히 각 class 당 하나의 예시만 있는 경우는 One-shot Learning(OSL)라고 불린다. 이 방식은 실제상황에 효과적이며 data 의존적인 학습을 극복할 수 있다.

![a](/assets/images/2025-07-30-GCN/Untitled-20250729211939471.webp)


## 2. Related Work

RGB 기반 이미지/비디오 Few-shot Learning의 경우 픽셀 기반 입력이기 때문에 각 frame에서 의미 있고 고정된 spatial local feature를 정의하기 어렵다. 

Skeleton-based action recognition에서는 다양한 연구가 일어나고 있으며, FSL 방식을 활용한 연구도 많이 진행 중이다.


## 3. Method

![a](/assets/images/2025-07-30-GCN/Untitled-20250729214659684.webp)

위 사진은 본 논문에서 제안하는 모델이다. 제안된 모델은 metric-based solution의 framework를 따르며, encoding backbone, embedder, linear metric-based classifier로 구성되어 있다. encoding backbone은 ST-GCN network를 채택했다. 


### 3.1 Encoding Architecture

![a](/assets/images/2025-07-30-GCN/aa.png)

ST-GCN을 사용한 feature extraction은 spatial 및 temporal convolution을 통해서 이루어지며, 식은 1~3번 식과 같다. ST-GCN은 skeleton을 신체 중심을 기준으로 퍼진 복잡한 그래프로 간주하며, 각 관절은 척추 중심까지의 거리를 기준으로 원심성, 구심성, root(자신) 관계로 구분된다. 

본 논문에서는 각 관절이 속한 신체 부위 내에서의 local 이웃 관계를 반영하는 $\bar{A}$를 추가로 설계하였다. 이는 아래의 그림을 통해서 확인할 수 있으며, 4번 5번식을 통해서 구해진다. 따라서 spatial convolution layer는 4개의 부위별 sub-graph와 1개의 global skeleton graph 총 5개의 병렬 convolution이 수행된다. 

temporal convolution layer는 각 관절 $v_i$에 대해서 $t' - 1$, $t'$, $t'+1$ 총 3개의 병렬 convolution이 수행된다. 

![a](/assets/images/2025-07-30-GCN/Untitled-20250729214728611.webp)

### 3.2 Part-based Global Representation

![a](/assets/images/2025-07-30-GCN/bb.png)

3.1의 방식으로 feature를 얻은 후 해당되는 관절과 시간 차원에 대해 segmented mean pooling을 적용해서 수행자의 시간 구간에 해당하는 신체 부위의 local embedding($g_{P^m_{ri}}$)을 얻는다. 이는 6번 식과 같이 구해지며, 시간 차원은 평균적으로 세 구간으로 나눠지며, $T_{div} = T_{feat} / 3$ 이다.

one-shot learning에서 episodic learning algorithm을 사용하는 경우, 각 epoch은 보조 dataset에서 무작위로 sample된 여러 subtask들로부터 meta learning이 이루어지며, 각 subtask는 N-way-1-shot 설정을 가진다. 

1-shot 학습 시나리오에서, 에피소드 기반 학습 알고리즘(episodic learning algorithm) [34]을 사용하는 경우, 각 에폭(epoch)은 보조 데이터셋(auxiliary set)에서 무작위로 샘플링된 여러 서브태스크들로부터 메타 학습됩니다. 각 서브태스크는 테스트 태스크와 동일한 N-way-1shot 설정을 가집니다.

모델 학습 시, 입력에 대해서 아래와 같이 각 클래스에 속할 확률 분포를 계산한다. 또한 학습 시 9.1번 식과 같이 음의 로그 확률 손실로 파라미터를 최적화 한다. test를 할 때는 9.2 와 같은 방식으로 예측된다.

![a](/assets/images/2025-07-30-GCN/cc.png)

### 3.3 Adaptive Dependency Learning

지금까지의 분류는 모든 비교 단위의 embedding 거리 합을 편향 없이 계산해서 유사도를 결정하지만 이러한 방식은 행동에 중요한 영역이나 노이즈가 많은 영역 또한 동일한 비중으로 취급하기 때문에 일반화 성능을 저해할 수 있다.

따라서 이를 해결하기 위해서 각 비교 단위의 중요도를 분배할 수 있는 self-attention 기반 모듈을 설계하였다. 이 모듈은 아래의 그림과 같다. 

![a](/assets/images/2025-07-30-GCN/Untitled-20250730131903029.webp)


세 개의 파라미터 행렬을 준비한 후 이를 각각 global representation과 곱한 후 행동 기반 맥락적 의존성을 포착하는 정규화된 attention score matrix를 생성한다. 이는 아래와 같이 계산된다. 또한 11번 식과 같이 instance-level constraint를 더해주어 최종적인 feature를 만들어낸다.

![a](/assets/images/2025-07-30-GCN/dd.png)

## 4. Experiments

NTU-RGB+D 120 dataset을 사용 100개의 class의 Training set와 20개의 class의 Test set으로 분할 되었다. Test set의 각 class는 오직 하나의 reference sample만 가진다.

general performance examination: 전체 100개 class의 Training set을 활용 모델을 학습
auxiliary reduction experiment: Training set 수를 20, 40, 60, 80, 100으로 변화하며 실험
여기에 더불어 Ablation study가 진행된다.

skeleton 데이터의 길이는 75 frame 길면 평균 frame sampling, 짧으면 zero-padding을 적용하였다. frontal-viewing pre-process을 적용하여서 데이터가 정면 방향을 보도록한다.

최대 100 epoch으로 학습하며 10 epoch동안 개선되지 않으면 early stopping, Adam optimizer cosine annealing schedular 사용, Learning rate $10^{-3} weigth decay $10^{-6}$
batch size 64, 각 학습의 sub-task는 20-way-1-shot 설정을 사용해서 학습

아래는 실험 결과이다.

![a](/assets/images/2025-07-30-GCN/Untitled-20250730135443670.webp)

![a](/assets/images/2025-07-30-GCN/Untitled-20250730135457904.webp)

![a](/assets/images/2025-07-30-GCN/Untitled-20250730135508379.webp)

![a](/assets/images/2025-07-30-GCN/Untitled-20250730135527990.webp)
